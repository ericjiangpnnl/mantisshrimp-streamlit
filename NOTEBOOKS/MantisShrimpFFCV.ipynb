{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9332fec-432c-42ad-b7d5-77e5fbbc50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from utils import my_transform\n",
    "\n",
    "class MantisShrimpDataset(Dataset):\n",
    "    def __init__(self, kind: str, WORLD_RANK:int =0, ZMAX: float=1.6):\n",
    "        assert kind in ['train','val','test']\n",
    "        \n",
    "        self.max = np.array([2.0336876,8.301209523105817,6.198499090528679]) #TODO\n",
    "        \n",
    "        csv_path1 = '/rcfs/projects/mantis_shrimp/mantis_shrimp/data/spectroscopy/redshifts_withextinction.pkl'\n",
    "        csv_path2 = '/rcfs/projects/mantis_shrimp/mantis_shrimp/data/redshifts_broken_beck/SDSS_MGS/MGS_qwsaz123.csv'\n",
    "        csv_path3 = '/rcfs/projects/mantis_shrimp/mantis_shrimp/data/redshifts_broken_beck/WISE_PS1_STRM.csv'\n",
    "        \n",
    "        DF = pd.read_pickle(csv_path1,)\n",
    "        DF_pas = pd.read_csv(csv_path2,usecols=['bestObjID','zphot'])\n",
    "        \n",
    "        DF_pas.drop_duplicates('bestObjID',inplace=True)\n",
    "        DF_pas_comb = pd.merge(DF,DF_pas,'left',left_on='photoObjID_survey',right_on='bestObjID')\n",
    "        DF_pas_comb = DF_pas_comb.drop('bestObjID',axis = 1)\n",
    "        DF = DF_pas_comb\n",
    "        DF_wps = pd.read_csv(csv_path3,\n",
    "                             usecols=['dstArcSec',\n",
    "                                      'cellDistance_Photoz',\n",
    "                                      'z_phot0',\n",
    "                                      'z_photErr',\n",
    "                                      'prob_Galaxy',\n",
    "                                      'photoObjID_survey']\n",
    "                             )\n",
    "        \n",
    "        DF = pd.merge(DF,DF_wps,how='left',on='photoObjID_survey')\n",
    "        \n",
    "        indices = np.load(f'/rcfs/projects/mantis_shrimp/mantis_shrimp/data/npy_blocks/{kind}_indices.npy', mmap_mode = 'r')\n",
    "        exists_mask = np.load('/rcfs/projects/mantis_shrimp/mantis_shrimp/data/exists_mask.npy', mmap_mode = 'r')\n",
    "        \n",
    "        #get the correct chunk's indices-- these match what is in img.\n",
    "        indices = indices[WORLD_RANK]\n",
    "        \n",
    "        \n",
    "        z = DF['z'].values\n",
    "        ebv_csfd = DF['ebv_csfd'].values\n",
    "        ebv_planck = DF['ebv_planck'].values\n",
    "        zphot_MGS = DF['zphot'].values\n",
    "        zphot_WPS = DF['z_phot0'].values\n",
    "        \n",
    "        #now apply indices to find the correct values for this chunk\n",
    "        z = z[indices]\n",
    "        ebv_csfd = ebv_csfd[indices]\n",
    "        ebv_planck = ebv_planck[indices]\n",
    "        zphot_MGS = zphot_MGS[indices]\n",
    "        zphot_WPS = zphot_WPS[indices]\n",
    "        exists_mask = exists_mask[indices]\n",
    "        \n",
    "        #Now we use a mixture of whether the data exists + whether it satisfies our ZMAX constraint to create a mask.\n",
    "        #unfortunately, we cannot mask img b/c it is a mmap array. So we need to create a dictionary mapping from indices\n",
    "        #the user would supply to the existing data in img.\n",
    "        \n",
    "        zmax_mask = z<ZMAX\n",
    "        total_mask = np.logical_and(exists_mask,zmax_mask) #both must be True to accept.\n",
    "        \n",
    "        self.z = z[total_mask]\n",
    "        self.ebv_csfd = ebv_csfd[total_mask]\n",
    "        self.ebv_planck = ebv_planck[total_mask]\n",
    "        self.zphot_MGS = zphot_MGS[total_mask]\n",
    "        self.zphot_WPS = zphot_WPS[total_mask]\n",
    "        \n",
    "        self.idx_to_imgidx = dict(zip(np.arange(total_mask.sum()),np.where(total_mask)[0]))\n",
    "        \n",
    "        \n",
    "        self.img = np.load(f'/rcfs/projects/mantis_shrimp/mantis_shrimp/data/npy_blocks/{kind}/mantis_shrimp_{WORLD_RANK}.npy',\n",
    "                mmap_mode='r')\n",
    "                             \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_imgidx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_indices = np.array([self.idx_to_imgidx[idx],])\n",
    "        idx = np.array([idx,])\n",
    "        img = self.img[img_indices]\n",
    "        if len(img.shape) == 1:\n",
    "            img = img[None,] #add leading batch dimension\n",
    "        \n",
    "        galex = img[:,0:2048]\n",
    "        panstarrs = img[:,2048:146548]\n",
    "        unwise = img[:,146548::]\n",
    "        \n",
    "        galex = rearrange(galex,'b (f h w) -> b f h w',f=2,h=32,w=32)\n",
    "        panstarrs = rearrange(panstarrs,'b (f h w) -> b f h w',f=5,h=170,w=170)\n",
    "        unwise = rearrange(unwise,'b (f h w) -> b f h w',f=2,h=32,w=32)\n",
    "        \n",
    "        #these Nones will add a leading batch dimension.\n",
    "        z = self.z[idx]\n",
    "        ebv_csfd = self.ebv_csfd[idx]\n",
    "        ebv_planck = self.ebv_planck[idx]\n",
    "        zphot_MGS = self.zphot_MGS[idx]\n",
    "        zphot_WPS = self.zphot_WPS[idx]\n",
    "        \n",
    "        #apply arcsinh scaling\n",
    "        galex = my_transform(galex,0.2) #TODO\n",
    "        panstarrs = my_transform(panstarrs,0.2)\n",
    "        unwise = my_transform(unwise,0.2)\n",
    "        \n",
    "        galex = galex/self.max[0]\n",
    "        panstarrs = panstarrs/self.max[1]\n",
    "        unwise = unwise/self.max[2]\n",
    "        \n",
    "        ebvs = np.concatenate([ebv_csfd,ebv_planck]).T\n",
    "        \n",
    "        z = z.squeeze()\n",
    "        \n",
    "        galex = galex.astype('float32')\n",
    "        panstarrs = panstarrs.astype('float32')\n",
    "        unwise = unwise.astype('float32')\n",
    "        z = z.astype('float32')\n",
    "        ebvs = ebvs.astype('float32')\n",
    "        zphot_MGS = zphot_MGS.astype('float32')\n",
    "        zphot_WPS = zphot_WPS.astype('float32')\n",
    "        \n",
    "        return galex, panstarrs, unwise, z, ebvs, zphot_MGS, zphot_WPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470e697-b042-4cc3-a27d-750520e68f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mantis_shrimp import datasets\n",
    "\n",
    "MSD = datasets.MantisShrimpDataset(kind='train',WORLD_RANK=0,ZMAX=1.6,loc='vast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047484d-cebf-4866-84d7-31281078bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c6527-5431-4bdf-b58c-73aa42857fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MantisShrimpDataset('train', WORLD_RANK = 0, ZMAX = 1.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f3618-20f3-46ca-a1b8-7268e89219e8",
   "metadata": {},
   "source": [
    "### USING FFCV for dataloading\n",
    "\n",
    "We use the FFCV module and a custom dataset defintion to speed up dataloading by 17x. First we need to write the dataset using FFCV's DatasetWriter module. We also need to know the shapes of any arrays we want to convert in advance, and we feed those into the NDArray field parameter. A key point is to match the datatypes of the input to what we specify in the DatasetWriter module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1262edbc-a7ff-4e55-9075-8832b5738dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                        | 0/188117 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mMantisShrimpDataset(kind, WORLD_RANK, ZMAX \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.6\u001b[39m, loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrcfs\u001b[39m\u001b[38;5;124m'\u001b[39m,to_torch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m writer \u001b[38;5;241m=\u001b[39m DatasetWriter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/rcfs/projects/mantis_shrimp/Adam/mantis_shrimp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWORLD_RANK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.beton\u001b[39m\u001b[38;5;124m'\u001b[39m, {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgalex\u001b[39m\u001b[38;5;124m'\u001b[39m: NDArrayField(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)), \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpanstarrs\u001b[39m\u001b[38;5;124m'\u001b[39m: NDArrayField(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m170\u001b[39m, \u001b[38;5;241m170\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzphot_WPS\u001b[39m\u001b[38;5;124m'\u001b[39m: NDArrayField(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     17\u001b[0m }, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_indexed_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ffcv/writer.py:297\u001b[0m, in \u001b[0;36mDatasetWriter.from_indexed_dataset\u001b[0;34m(self, dataset, indices, chunksize, shuffle_indices)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# We add indices to the indices so that workers know where\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# to write in the metadata array\u001b[39;00m\n\u001b[1;32m    295\u001b[0m indices: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(indices))\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_common\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mworker_job_indexed_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ffcv/writer.py:255\u001b[0m, in \u001b[0;36mDatasetWriter._write_common\u001b[0;34m(self, num_samples, queue_content, work_fn, extra_worker_args)\u001b[0m\n\u001b[1;32m    253\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(diff)\n\u001b[1;32m    254\u001b[0m     previous \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m--> 255\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m progress\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Wait for all the workers to be done and get their allocations\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 108, in flush_page\n",
      "    self.fp.write(self.page_data.tobytes())\n",
      "KeyboardInterrupt\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/people/tsou806/.conda/envs/ntkenvironment/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 113, in worker_job_indexed_dataset\n",
      "    handle_sample(sample, dest_ix, field_names, metadata, allocator, fields)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/writer.py\", line 51, in handle_sample\n",
      "    field.encode(destination, field_value, allocator.malloc)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/fields/ndarray.py\", line 98, in encode\n",
      "    destination[0], data_region = malloc(self.element_size)\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 43, in malloc\n",
      "    self.flush_page()\n",
      "  File \"/people/tsou806/.local/lib/python3.9/site-packages/ffcv/memory_allocator.py\", line 89, in flush_page\n",
      "    sleep(0.001)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import NDArrayField, FloatField\n",
    "from mantis_shrimp import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Loop through dataset partitions and world ranks to write datasets to disk\n",
    "for kind in ['train', 'val', 'test']:\n",
    "    for WORLD_RANK in range(16):\n",
    "         # Initialize MantisShrimp dataset\n",
    "        dataset = datasets.MantisShrimpDataset(kind, WORLD_RANK, ZMAX =1.6, loc = 'rcfs',to_torch = False, mmap = True)\n",
    "        # Initialize DatasetWriter with specified fields and output file path\n",
    "        writer = DatasetWriter(f'/rcfs/projects/mantis_shrimp/Adam/mantis_shrimp_{kind}_{WORLD_RANK}.beton', {\n",
    "            'galex': NDArrayField(shape=(1, 2, 32, 32), dtype=np.dtype('float32')), \n",
    "            'panstarrs': NDArrayField(shape=(1, 5, 170, 170), dtype=np.dtype('float32')),\n",
    "            'unwise': NDArrayField(shape=(1, 2, 32, 32), dtype=np.dtype('float32')),\n",
    "            'z': FloatField(),\n",
    "            'ebvs': NDArrayField(shape=(2,), dtype=np.dtype('float32')),\n",
    "            'zphot_MGS': NDArrayField(shape=(1,), dtype=np.dtype('float32')),\n",
    "            'zphot_WPS': NDArrayField(shape=(1,), dtype=np.dtype('float32')),\n",
    "        }, num_workers=16) # Number of worker threads to use for writing\n",
    "        # Write the dataset to disk from the indexed dataset\n",
    "        writer.from_indexed_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a79a83-9a05-4847-8024-6f5d9d16ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.from_indexed_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827da99-c875-4158-b839-c729590f85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.transforms import ToTensor, ToDevice\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.fields.decoders import NDArrayDecoder, FloatDecoder\n",
    "PIPELINES = {\n",
    "  'galex': [NDArrayDecoder(), ToTensor(), ToDevice(torch.device('cuda'), non_blocking=True)],\n",
    "  'panstarrs': [NDArrayDecoder(), ToTensor()],\n",
    "  'unwise': [NDArrayDecoder(), ToTensor()],\n",
    "  'z' : [FloatDecoder(), ToTensor()],\n",
    "  'ebvs' : [NDArrayDecoder(), ToTensor()],\n",
    "  'zphot_MGS': [NDArrayDecoder(), ToTensor()],\n",
    "  'zphot_WPS': [NDArrayDecoder(), ToTensor()],\n",
    "}\n",
    "\n",
    "ORDERING = OrderOption.QUASI_RANDOM\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "loader = Loader('/rcfs/projects/mantis_shrimp/Adam/test.beton',\n",
    "                batch_size=BATCH_SIZE,\n",
    "                num_workers=NUM_WORKERS,\n",
    "                order=ORDERING,\n",
    "                pipelines=PIPELINES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0a070-6ae4-4538-bf65-1cc412a2d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(loader): \n",
    "    print(data[0], data[1], data[2], data[3], data[4], data[5], data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004ecfe-a5e9-4eaf-abe5-d949486356e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a903952-8b46-4b94-95fe-6390e7a51b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ad5e9-9d34-418b-8606-54f292503244",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b992cf-3bc2-4263-bb86-ad8fe20a11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e444c4-65d2-4914-b2f6-6a9a0843cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2aa50-f7d4-4d8b-813b-f271e1955ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dec570-8651-4377-9e8a-b90d248c923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b63822-2011-497a-92e9-7cb9ee0ec9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26859"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mantis_shrimp import datasets\n",
    "\n",
    "len(datasets.MantisShrimpDataset(kind='val',WORLD_RANK=0,ZMAX=1.6,loc='vast'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e43fee-8f84-4875-97b2-00c24819520c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
