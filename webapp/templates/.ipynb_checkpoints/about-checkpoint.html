<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="{{ url_for('static',filename='css/main.css')}}"/>
    <script type="module" src="https://cdn.jsdelivr.net/npm/zero-md@3?register"></script>
    <title>Photometric Redshift Visualization</title>
</head>
<body>
     <div id="wrap">
    <header>
        <nav class="navbar navbar-expand-lg navbar-light bg-light">
            <a class="navbar-brand" href="{{ url_for('index') }}">Redshift Viz</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item active">
                        <a class="nav-link" href="{{ url_for('index') }}">Home <span class="sr-only">(current)</span></a>
                    </li>
                    <li class="nav-item">
                        <a href="{{ url_for('about') }}" class="nav-link {% if about %}active{% endif %}">About</a>
                    </li>
                    <li class="nav-item">
                        <a href="#" class="nav-link {% if about %}active{% endif %}">Paper</a>

                    </li>
                </ul>
            </div>
        </nav>
    </header>
    <div class="container content-wrapper mt-5 mb-5">
    <zero-md>
      <!-- Write your markdown inside a `<script type="text/markdown">` tag -->
      <script type="text/markdown">
## Using FFCV to speed up dataloading by up to 17x. 

- We use MIT's FFCV module to speed up dataloading by **17x** compared to PyTorch's built in dataloader. 
- This requires two steps: writing the dataset to FFCV's .beton files, and reading them using FFCV's own dataloader.
- In order to write the dataset, we use FFCV's DatasetWriter module. Since we are writing numpy arrays, we use NDArrayFields and FloatFields in order to record the data. 
- The first argument for DatasetWriter is a path to the .beton file it writes. The second argument is a dictionary where we assign variables to input data. The last argument we specify is the number of workers for this job. 
- We have to specify the dimensions of each array we want to write, and we can do this using the field's "shape" parameter. 
- In addition, we have to make sure that the datatype we write the data to matches our input. Since we are writing arrays with numpy float32's, we cast the input data as float32 arrays.
- Below is an example of how we use FFCV to write our custom dataset for the Mantis Shrimp project. 
          
```          
from ffcv.writer import DatasetWriter
from ffcv.fields import NDArrayField, FloatField
from mantis_shrimp import datasets
import numpy as np

for kind in ['train', 'val', 'test']:
    for WORLD_RANK in range(16):
        dataset = datasets.MantisShrimpDataset(kind, WORLD_RANK, ZMAX =1.6, loc = 'rcfs',to_torch = False, mmap = True)
        writer = DatasetWriter(f'/{path}/mantis_shrimp_{kind}_{WORLD_RANK}.beton', {
            'galex': NDArrayField(shape=(1, 2, 32, 32), dtype=np.dtype('float32')), 
            'panstarrs': NDArrayField(shape=(1, 5, 170, 170), dtype=np.dtype('float32')),
            'unwise': NDArrayField(shape=(1, 2, 32, 32), dtype=np.dtype('float32')),
            'z': FloatField(),
            'ebvs': NDArrayField(shape=(2,), dtype=np.dtype('float32')),
            'zphot_MGS': NDArrayField(shape=(1,), dtype=np.dtype('float32')),
            'zphot_WPS': NDArrayField(shape=(1,), dtype=np.dtype('float32')),
        }, num_workers=16)
        writer.from_indexed_dataset(dataset)     
```
- FFCV's loader module functions as a drop in replacement for PyTorch's built in dataloader object.
- Additionally, FFCV has optimized certain subroutines such as converting from their file format to Torch tensors, as well as loading the data to a GPU. 
- You can choose between a sequential, quasirandom and random ordering for the loader. Both sequential and quasirandom orderings load a few batches of data at a time and consume far less memory than the random ordering which loads the whole dataset in ram. 
- We use NDArray and Float decoders in order to process the .beton files. 
- It is important to make sure that the keys are the same as the ones used when writing the dataset. 
```
from ffcv.transforms import ToTensor, ToDevice
from ffcv.loader import Loader, OrderOption
from ffcv.fields.decoders import NDArrayDecoder, FloatDecoder
PIPELINES = {
  'galex': [NDArrayDecoder(), ToTensor(), ToDevice(torch.device('cuda'), non_blocking=True)],
  'panstarrs': [NDArrayDecoder(), ToTensor()],
  'unwise': [NDArrayDecoder(), ToTensor()],
  'z' : [FloatDecoder(), ToTensor()],
  'ebvs' : [NDArrayDecoder(), ToTensor()],
  'zphot_MGS': [NDArrayDecoder(), ToTensor()],
  'zphot_WPS': [NDArrayDecoder(), ToTensor()],
}

ORDERING = OrderOption.QUASI_RANDOM

BATCH_SIZE = 32

NUM_WORKERS = 8

loader = Loader('{path}/test.beton',
                batch_size=BATCH_SIZE,
                num_workers=NUM_WORKERS,
                order=ORDERING,
                pipelines=PIPELINES)
```
- Installing FFCV may require tweaks depending on your environment. We found it helpful to install using the latest version of conda and compilers set equal to 1.2.0.
## Using our API to query the Mantis Shrimp model. 
- You can query the database using curl. Here is an example of how to do so. 
```
curl -X POST -d '{"NAME": 0, "RA":197.614455643, "DEC": 18.438168854}' localhost:5000/predict
```
- `curl` is a command for transfering data. 
- `-X POST` specifies the HTTP method we are using--in this case, POST. 
-  `-d` specifies the data we are sending to the model. We format the data in a dictionary object which can be processed by our model. The model takes three arguments: "Name" (an id for your request), "RA" (right ascension), and "DEC" (declination).
- Finally, we provide the url to the API. 
- We can also use the requests library to query the model. The following code snippet can be integrated into a python script for querying our model. The main advantage is that the requests library checks the website to see if the query was successful. 
```
import requests
 
# URL of the Flask API (adjust if necessary)
url = 'http://127.0.0.1:5000/predict'
 
# Prepare the data payload as a dictionary
data = {"NAME": 0, "RA":197.614455643, "DEC": 18.438168854}  # Example: sending data to our API
 
# Send the POST request
response = requests.post(url, json=data)
 
# Check if the request was successful
if response.status_code == 200:
    print("Success!")
    print("Response data:", response.json())  # Print the response data from the server
else:
    print("Failed to retrieve data")
    print("Status code:", response.status_code)
    print("Response text:", response.text)  # Display response text which might contain the error
```
      </script>
    </zero-md>
    </div>

        <footer class="footer fixed-bottom container">
          <div class="container">
        <p>&copy; 2023 AstroWeb. All rights reserved.</p>
        <p>
            <a href="/terms">Terms of Use</a> | 
            <a href="/privacy">Privacy Policy</a>
        </p>
    </footer>
    </div> 
</body>
</html>    